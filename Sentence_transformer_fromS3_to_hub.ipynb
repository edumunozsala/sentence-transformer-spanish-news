{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7e772c8",
   "metadata": {},
   "source": [
    "## Installing the git LFS fylesystem support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5ef1ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected operating system as amzn/2.\n",
      "Checking for curl...\n",
      "Detected curl...\n",
      "Downloading repository file: https://packagecloud.io/install/repositories/github/git-lfs/config_file.repo?os=amzn&dist=2&source=script\n",
      "done.\n",
      "Installing pygpgme to verify GPG signatures...\n",
      "Loaded plugins: dkms-build-requires, extras_suggestions, langpacks, priorities,\n",
      "              : update-motd, versionlock\n",
      "amzn2-core                                               | 3.7 kB     00:00     \n",
      "amzn2extra-docker                                        | 3.0 kB     00:00     \n",
      "amzn2extra-kernel-5.10                                   | 3.0 kB     00:00     \n",
      "centos-extras                                            | 2.9 kB     00:00     \n",
      "copr:copr.fedorainfracloud.org:vbatts:shadow-utils-newxi | 3.3 kB     00:00     \n",
      "https://download.docker.com/linux/centos/2/x86_64/stable/repodata/repomd.xml: [Errno 14] HTTPS Error 404 - Not Found\n",
      "Trying other mirror.\n",
      "github_git-lfs-source/signature                          |  833 B     00:00     \n",
      "Retrieving key from https://packagecloud.io/github/git-lfs/gpgkey\n",
      "Importing GPG key 0xDC282033:\n",
      " Userid     : \"https://packagecloud.io/github/git-lfs (https://packagecloud.io/docs#gpg_signing) <support@packagecloud.io>\"\n",
      " Fingerprint: 6d39 8dbd 30dd 7894 1e2c 4797 fe2a 5f8b dc28 2033\n",
      " From       : https://packagecloud.io/github/git-lfs/gpgkey\n",
      "github_git-lfs-source/signature                          | 1.8 kB     00:00 !!! \n",
      "libnvidia-container/x86_64/signature                     |  833 B     00:00     \n",
      "libnvidia-container/x86_64/signature                     | 2.1 kB     00:00 !!! \n",
      "neuron                                                   | 2.9 kB     00:00     \n",
      "nvidia-container-runtime/x86_64/signature                |  833 B     00:00     \n",
      "nvidia-container-runtime/x86_64/signature                | 2.1 kB     00:00 !!! \n",
      "nvidia-docker/x86_64/signature                           |  833 B     00:00     \n",
      "nvidia-docker/x86_64/signature                           | 2.1 kB     00:00 !!! \n",
      "neuron/primary_db                                          |  95 kB   00:00     \n",
      "github_git-lfs-source/primary                              | 5.2 kB   00:00     \n",
      "github_git-lfs-source                                                     49/49\n",
      "61 packages excluded due to repository priority protections\n",
      "Package pygpgme-0.3-9.amzn2.0.3.x86_64 already installed and latest version\n",
      "Nothing to do\n",
      "Installing yum-utils...\n",
      "Loaded plugins: dkms-build-requires, extras_suggestions, langpacks, priorities,\n",
      "              : update-motd, versionlock\n",
      "https://download.docker.com/linux/centos/2/x86_64/stable/repodata/repomd.xml: [Errno 14] HTTPS Error 404 - Not Found\n",
      "Trying other mirror.\n",
      "neuron                                                   | 2.9 kB     00:00     \n",
      "61 packages excluded due to repository priority protections\n",
      "Package yum-utils-1.1.31-46.amzn2.0.1.noarch already installed and latest version\n",
      "Nothing to do\n",
      "Generating yum cache for github_git-lfs...\n",
      "Importing GPG key 0xDC282033:\n",
      " Userid     : \"https://packagecloud.io/github/git-lfs (https://packagecloud.io/docs#gpg_signing) <support@packagecloud.io>\"\n",
      " Fingerprint: 6d39 8dbd 30dd 7894 1e2c 4797 fe2a 5f8b dc28 2033\n",
      " From       : https://packagecloud.io/github/git-lfs/gpgkey\n",
      "Generating yum cache for github_git-lfs-source...\n",
      "\n",
      "The repository is setup! You can now install packages.\n",
      "Loaded plugins: dkms-build-requires, extras_suggestions, langpacks, priorities,\n",
      "              : update-motd, versionlock\n",
      "https://download.docker.com/linux/centos/2/x86_64/stable/repodata/repomd.xml: [Errno 14] HTTPS Error 404 - Not Found\n",
      "Trying other mirror.\n",
      "neuron                                                   | 2.9 kB     00:00     \n",
      "61 packages excluded due to repository priority protections\n",
      "Resolving Dependencies\n",
      "--> Running transaction check\n",
      "---> Package git-lfs.x86_64 0:3.2.0-1.el7 will be installed\n",
      "--> Finished Dependency Resolution\n",
      "\n",
      "Dependencies Resolved\n",
      "\n",
      "================================================================================\n",
      " Package        Arch          Version               Repository             Size\n",
      "================================================================================\n",
      "Installing:\n",
      " git-lfs        x86_64        3.2.0-1.el7           github_git-lfs        3.5 M\n",
      "\n",
      "Transaction Summary\n",
      "================================================================================\n",
      "Install  1 Package\n",
      "\n",
      "Total download size: 3.5 M\n",
      "Installed size: 10 M\n",
      "Downloading packages:\n",
      "git-lfs-3.2.0-1.el7.x86_64.rpm                             | 3.5 MB   00:00     \n",
      "Running transaction check\n",
      "Running transaction test\n",
      "Transaction test succeeded\n",
      "Running transaction\n",
      "Warning: RPMDB altered outside of yum.\n",
      "  Installing : git-lfs-3.2.0-1.el7.x86_64                                   1/1 \n",
      "Git LFS initialized.\n",
      "  Verifying  : git-lfs-3.2.0-1.el7.x86_64                                   1/1 \n",
      "\n",
      "Installed:\n",
      "  git-lfs.x86_64 0:3.2.0-1.el7                                                  \n",
      "\n",
      "Complete!\n",
      "Git LFS initialized.\n"
     ]
    }
   ],
   "source": [
    "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.rpm.sh | sudo bash\n",
    "!sudo yum install git-lfs -y\n",
    "!git lfs install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5603fb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 KB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n",
      "  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from sentence-transformers) (4.62.3)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from sentence-transformers) (1.10.0)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from sentence-transformers) (0.11.1)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from sentence-transformers) (1.21.2)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from sentence-transformers) (1.0.1)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: nltk in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from sentence-transformers) (3.6.5)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
      "  Downloading huggingface_hub-0.9.0-py3-none-any.whl (120 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.5/120.5 KB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.0.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.11.10)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from nltk->sentence-transformers) (8.0.3)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from nltk->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from scikit-learn->sentence-transformers) (3.0.0)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from torchvision->sentence-transformers) (9.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.8)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=6340e81ab1e22f083dcd4a34331e0c02c9861a2e804f086963383a28f5c5ad00\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/5e/6f/8c/d88aec621f3f542d26fac0342bef5e693335d125f4e54aeffe\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: tokenizers, sentencepiece, huggingface-hub, transformers, sentence-transformers\n",
      "Successfully installed huggingface-hub-0.9.0 sentence-transformers-2.2.2 sentencepiece-0.1.97 tokenizers-0.12.1 transformers-4.21.2\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p38/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip install \"transformers==4.12.3\" --upgrade\n",
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce0b0727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the my final model name\n",
    "mymodel_name='bertin-sts-cc-news-es'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a33df488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.101.1\n",
      "sagemaker role arn: arn:aws:iam::223817798831:role/workshop-sagemaker-kfp-role\n",
      "sagemaker bucket: edumunozsala-ml-sagemaker\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "print(sagemaker.__version__)\n",
    "\n",
    "# Specify your bucket name\n",
    "bucket_name = 'edumunozsala-ml-sagemaker'\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "# Specify your bucket name\n",
    "sagemaker_session_bucket= bucket_name\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "region = sess.boto_session.region_name\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b08eb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "local_path = mymodel_name\n",
    "# Set the S3 folder containing the model.tar.gz file\n",
    "model_data= 's3://edumunozsala-ml-sagemaker/sentence-transformer-spanish/huggingface-pytorch-training-2022-08-22-17-33-29-910/output'\n",
    "\n",
    "os.makedirs(local_path, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219685c1",
   "metadata": {},
   "source": [
    "Download the model file from S3 to a local folder and unzip the tar.gz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "026c6c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download model from S3\n",
    "S3Downloader.download(\n",
    "    s3_uri=model_data, # s3 uri where the trained model is located\n",
    "    local_path=local_path, # local path where *.tar.gz will be saved\n",
    "    sagemaker_session=sess # sagemaker session used for training the model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e1c01fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip model if it is a model.tar.gz file\n",
    "tar = tarfile.open(f\"{local_path}/model.tar.gz\", \"r:gz\")\n",
    "tar.extractall(path=local_path)\n",
    "tar.close()\n",
    "os.remove(f\"{local_path}/model.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d37896d",
   "metadata": {},
   "source": [
    "## Create the Sentence Transformer model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e39cec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4ffd211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bertin-sts-cc-news-es/\n"
     ]
    }
   ],
   "source": [
    "local_path= local_path +'/'\n",
    "print(local_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1bf8f1",
   "metadata": {},
   "source": [
    "Instantiate a SentenceTransformer model from the loca files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70ac9952",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a306ce07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.24001510e-01 -6.41292632e-01  6.75440907e-01  2.48697214e-02\n",
      " -1.39843198e-02  2.95864761e-01 -9.00002643e-02  6.84070230e-01\n",
      "  1.65867675e-02  1.04857393e-01  2.14992240e-02 -1.37010172e-01\n",
      "  5.51612139e-01 -7.18234405e-02 -2.77047325e-02  7.49606043e-02\n",
      " -2.68262208e-01 -3.05915207e-01 -6.03006035e-02 -3.52383077e-01\n",
      "  9.73617956e-02  5.01497388e-02  2.02847958e-01 -5.72251081e-02\n",
      "  1.02436110e-01 -8.14587250e-03  2.98103213e-01  8.04232776e-01\n",
      " -9.67485458e-02  4.57457989e-01  4.43778336e-01 -1.07228473e-01\n",
      "  5.73192060e-01 -4.62076545e-01  1.93420649e-01  3.55567671e-02\n",
      " -3.92334014e-01  4.76867855e-01  2.19832227e-01  7.28959799e-01\n",
      "  4.38820183e-01  3.68073106e-01  3.43763798e-01  9.22128707e-02\n",
      "  6.78275287e-01  3.23260486e-01 -1.03598051e-02  8.82733539e-02\n",
      "  3.24270517e-01  4.01368737e-01 -3.39212865e-01 -1.71711251e-01\n",
      " -1.51579633e-01  3.75644803e-01  1.48562565e-01  3.14270854e-01\n",
      "  2.31097788e-01  5.26751101e-01  1.43302068e-01  4.26166534e-01\n",
      "  2.00777620e-01  1.35035083e-01  4.88473117e-01 -1.74552977e-01\n",
      "  3.28715473e-01  1.71416938e-01 -2.63568789e-01 -3.19453478e-01\n",
      "  6.93496168e-02  7.61279523e-01 -1.30124152e-01  8.66801739e-02\n",
      "  2.65353560e-01  2.74900436e-01 -7.34497327e-03 -1.07029989e-01\n",
      "  1.96544364e-01 -6.50001094e-02 -2.30890840e-01 -5.66256940e-01\n",
      "  3.16879570e-01  2.60577559e-01  5.90050757e-01 -3.34841013e-03\n",
      " -5.20501494e-01 -2.02889100e-01  1.62221491e-01 -1.67399511e-01\n",
      " -2.56648272e-01  1.27007272e-02 -1.23712257e-01  1.68908704e-02\n",
      "  2.15663284e-01 -3.87321293e-01  4.54498023e-01  3.50644529e-01\n",
      "  7.42670596e-02 -3.73145223e-01  1.49263635e-01  5.33844769e-01\n",
      " -2.49990150e-02 -3.52822065e-01  3.70767415e-01 -4.92646515e-01\n",
      "  1.50740609e-01 -1.81910053e-01  2.87806779e-01 -4.20656025e-01\n",
      " -3.26060772e-01  1.15415715e-01 -2.63252139e-01  1.74476519e-01\n",
      " -1.20856315e-01  2.80940622e-01  2.40864798e-01 -5.87019384e-01\n",
      "  6.24166250e-01  2.63446897e-01  1.89321801e-01 -3.61175090e-02\n",
      " -7.32376650e-02  9.31835100e-02 -4.73476678e-01  4.75266814e-01\n",
      "  3.04793194e-02  4.39368457e-01 -7.42327631e-01 -1.12242520e+00\n",
      "  2.02088073e-01 -2.45389715e-01  5.18991724e-02 -1.66290812e-02\n",
      "  7.81824440e-02 -5.60284816e-02 -5.51839322e-02  2.87543863e-01\n",
      " -5.44089735e-01 -6.22813940e-01 -3.60406488e-01  5.12526371e-02\n",
      "  1.62434340e-01  2.15564013e-01 -1.21980123e-01 -6.70354128e-01\n",
      "  7.10708559e-01  3.25091094e-01  2.40589276e-01  2.56625205e-01\n",
      "  3.47300619e-01  5.93126297e-01 -3.78187895e-02  2.84981847e-01\n",
      "  4.18984324e-01 -7.39553511e-01  7.85639286e-02  2.44983256e-01\n",
      " -7.21149147e-01  3.63461711e-02 -6.28149509e-01  1.55325547e-01\n",
      " -5.96761927e-02 -4.15150851e-01  5.39995253e-01  2.76948363e-01\n",
      "  1.09970421e-01 -4.66111302e-02 -4.96953219e-01 -7.67824113e-01\n",
      " -9.14490297e-02 -7.71862745e-01 -2.09126815e-01 -5.97076789e-02\n",
      "  2.47689709e-03 -3.09570730e-01  5.26889920e-01  7.19188750e-02\n",
      " -5.57159662e-01  5.95588349e-02  3.04127008e-01 -8.66313398e-01\n",
      "  2.68212795e-01  6.33737564e-01  4.27959085e-01  2.98078507e-01\n",
      " -2.10844427e-01  4.95103151e-01  2.10746959e-01  5.69336712e-01\n",
      " -1.14782657e-02 -1.68912277e-01  3.30298066e-01 -9.19520184e-02\n",
      "  1.01598576e-01  8.79241973e-02 -1.38804793e-01 -7.73010179e-02\n",
      "  3.57941836e-01 -4.87541169e-01  4.93786633e-01 -4.45578853e-03\n",
      "  5.66587567e-01  7.50094801e-02  5.75959623e-01  3.50805342e-01\n",
      "  2.79748321e-01 -4.88779694e-02  4.12874877e-01  2.49370441e-01\n",
      "  1.17213801e-01  3.52192760e-01  1.29641950e-01 -8.78100470e-02\n",
      "  7.91420162e-01 -6.06294632e-01  5.55944480e-02 -1.88001767e-01\n",
      " -8.24762788e-03  6.89992905e-01 -1.73747405e-01 -7.48898923e-01\n",
      " -8.16000164e-01  2.76175261e-01  3.09392065e-01 -2.64690250e-01\n",
      " -5.49543381e-01 -4.44390267e-01 -6.64142191e-01  1.11638851e-01\n",
      "  8.92642513e-02 -2.33449414e-02 -5.52885592e-01  4.37063575e-01\n",
      " -2.83228815e-01  6.75831854e-01  3.47691417e-01  6.27230048e-01\n",
      "  5.06386254e-03  5.39436877e-01  8.64785194e-01 -8.75983536e-02\n",
      "  8.68830606e-02 -1.19103320e-01  3.40274215e-01  9.82403308e-02\n",
      " -4.91005808e-01  4.70649987e-01 -1.01911351e-01  1.20638637e-02\n",
      "  4.81078140e-02 -6.39071882e-01 -6.46435499e-01  4.28485841e-01\n",
      " -3.32043558e-01 -2.64176965e-01 -3.00892815e-02  6.48897588e-01\n",
      " -4.49633151e-01 -4.01719481e-01 -3.03966492e-01  1.06203429e-01\n",
      " -1.59248203e-01  1.71324834e-01 -4.25937295e-01 -3.12947363e-01\n",
      " -2.11450800e-01 -5.18751085e-01  1.99284721e-02 -1.73017859e-01\n",
      " -5.11492230e-02 -3.33248854e-01  3.13154250e-01  1.97266061e-02\n",
      "  4.53413606e-01 -4.60509568e-01 -2.11230457e-01 -2.26397380e-01\n",
      " -4.03528124e-01  1.09483767e+00  5.39535165e-01 -6.78219676e-01\n",
      " -9.31812823e-02 -2.63195515e-01 -1.83575779e-01  2.88311034e-01\n",
      " -1.97929323e-01  6.47743165e-01  2.79452384e-01 -9.14943159e-01\n",
      " -3.40350807e-01  4.40222055e-01 -1.19001195e-01  3.54598165e-02\n",
      "  2.83540517e-01 -1.75530925e-01  6.50352165e-02 -8.76046941e-02\n",
      " -2.90569037e-01  1.73131570e-01 -1.85560773e-03  3.06573629e-01\n",
      " -7.63267130e-02  9.94787991e-01  5.72264828e-02 -3.35555434e-01\n",
      "  1.76254377e-01 -3.29114705e-01  2.32160434e-01  3.73125762e-01\n",
      " -7.08654448e-02 -2.17862502e-01 -9.87524092e-02 -1.53387859e-01\n",
      " -7.07930624e-01 -2.53283709e-01  1.28812835e-01 -4.90756720e-01\n",
      "  2.80421257e-01 -4.64750588e-01  3.25045101e-02 -6.82041347e-02\n",
      "  1.61215127e-01  5.56482635e-02  1.53971687e-01 -2.66601115e-01\n",
      "  1.65586006e-02  8.36278975e-01 -8.21186155e-02  1.62351176e-01\n",
      "  4.06780630e-01  2.11642683e-01  4.30976115e-02 -5.82065880e-01\n",
      " -6.25860453e-01 -5.32585345e-02  5.02687991e-01  2.08758060e-02\n",
      " -2.82629058e-02 -4.68683600e-01  5.25467768e-02 -7.77703881e-01\n",
      " -1.02313951e-01  5.54198980e-01  2.78225869e-01 -2.59390146e-01\n",
      "  2.51658320e-01  5.22585690e-01 -2.28356943e-01  1.01651765e-01\n",
      "  5.60945451e-01  3.90098184e-01 -3.85103196e-01 -3.92904848e-01\n",
      "  1.57662734e-01  6.87384531e-02 -6.83285415e-01 -2.87828088e-01\n",
      " -1.75584152e-01 -3.82643819e-01  8.19653153e-01 -1.77609980e-01\n",
      "  5.66101134e-01 -8.49440992e-01  7.80207217e-02 -2.51188219e-01\n",
      " -6.88970327e-01 -4.68974710e-01  2.68144369e-01  6.94155514e-01\n",
      "  5.48710003e-02 -4.43372905e-01  6.13329828e-01  5.92264272e-02\n",
      "  2.22537201e-02 -2.60156542e-01 -5.75901605e-02  1.03713483e-01\n",
      "  1.31896913e-01  1.78747028e-02 -3.28238517e-01  2.59265810e-01\n",
      "  1.18157022e-01 -3.24928425e-02  2.01730639e-01 -1.59096748e-01\n",
      "  1.75907224e-01  5.89333149e-03 -5.85297823e-01  5.88043869e-01\n",
      " -3.08363706e-01 -4.14768219e-01  2.83541143e-01  3.69315967e-02\n",
      " -9.90965143e-02 -1.19521625e-01 -8.00777748e-02  9.66620445e-02\n",
      " -9.33218449e-02 -6.23017490e-01 -1.37112290e-01 -7.45014288e-03\n",
      "  3.48696619e-01  1.55124813e-01  2.52892733e-01  6.60821497e-01\n",
      "  8.75196233e-02  6.23931885e-01  2.92747945e-01  7.55378678e-02\n",
      "  5.08457780e-01  3.40678960e-01  1.44850060e-01  4.75128204e-01\n",
      "  1.20328993e-01  3.37186418e-02 -4.91754353e-01  4.79556829e-01\n",
      "  3.75088871e-01  1.39580473e-01  1.91048253e-02 -1.21819302e-01\n",
      " -8.25077057e-01 -5.87645888e-01 -4.23257172e-01 -3.97192448e-01\n",
      " -3.49015370e-02 -7.92470574e-01  4.33596611e-01  4.83276486e-01\n",
      "  1.89016685e-01  1.68149173e-01  7.64434099e-01 -5.03468156e-01\n",
      " -7.94302672e-02  1.27832198e+00  3.47322077e-01 -2.91776687e-01\n",
      "  1.73878297e-01 -1.45357311e-01 -9.97047424e-01  4.18138504e-01\n",
      "  7.68320262e-01 -1.51561871e-01  3.22305501e-01 -7.74531782e-01\n",
      " -3.23750138e-01  3.55182469e-01 -3.41345072e-01 -4.93930042e-01\n",
      "  6.61849454e-02  6.41514897e-01 -7.88869783e-02  1.49240752e-03\n",
      "  6.81878924e-02 -4.54611957e-01 -1.99872077e-01 -5.67228913e-01\n",
      " -3.06770261e-02  4.77807224e-01 -1.40849963e-01  5.47271967e-01\n",
      " -5.73551282e-02  1.29339829e-01  5.50888777e-02 -2.06377618e-02\n",
      " -8.45265836e-02 -4.18917447e-01  8.70821178e-02  5.09156644e-01\n",
      "  4.44898695e-01 -4.53228690e-02  2.82470345e-01 -4.96087432e-01\n",
      "  3.03787719e-02 -1.91028059e-01 -6.22889459e-01 -4.82126743e-01\n",
      " -4.64352146e-02 -5.48557222e-01  6.79792941e-01 -2.26707876e-01\n",
      "  3.39817643e-01  2.13997319e-01 -2.00943366e-01 -5.53318858e-01\n",
      "  1.37348130e-01 -6.35051057e-02 -3.18423271e-01  3.60253930e-01\n",
      " -7.81441256e-02  1.31455004e-01  3.67199332e-02 -7.15239406e-01\n",
      " -2.78110623e-01  3.64709973e-01  1.59645662e-01  2.65562255e-02\n",
      "  3.50222498e-01 -3.48327041e-01  1.85185015e-01  4.04058725e-01\n",
      " -2.68066376e-01 -1.20712064e-01 -3.59319733e-03 -3.61505926e-01\n",
      " -5.25268316e-01 -3.20326835e-02 -4.76433188e-01 -5.91528118e-01\n",
      " -2.53399700e-01  6.77863598e-01  2.59046983e-02 -8.68853211e-01\n",
      "  7.19983354e-02  4.59515750e-01  1.94195285e-01  7.15804815e-01\n",
      "  9.98708084e-02  6.78496659e-02  2.59710819e-01 -2.98035264e-01\n",
      "  3.58014971e-01  1.60631880e-01 -1.43296793e-01  4.53318382e-04\n",
      " -6.51085451e-02  2.42650375e-01  4.06308807e-02 -8.89099658e-01\n",
      " -1.79884687e-01 -1.91019595e-01  7.80068189e-02 -4.51878935e-01\n",
      "  2.98932362e-02  5.64406455e-01  1.93137392e-01 -2.28850782e-01\n",
      "  1.63560584e-01  3.59207273e-01 -5.25214553e-01  4.40726876e-01\n",
      " -1.27928630e-01 -2.71605104e-01 -2.30682850e-01  4.64175820e-01\n",
      " -2.71321148e-01 -2.45071039e-01 -1.18985482e-01  7.23922029e-02\n",
      " -8.27797353e-02 -8.10804009e-01 -1.38126001e-01 -3.96343786e-03\n",
      "  1.73211709e-01 -3.98439676e-01 -5.48930466e-01 -4.31871504e-01\n",
      "  1.59404367e-01 -5.23404062e-01  6.07789271e-02  4.73990813e-02\n",
      " -1.56679407e-01  3.91124278e-01  1.39724791e-01 -9.55961645e-02\n",
      " -4.86893654e-02 -8.04728419e-02  6.42300397e-02  3.17882985e-01\n",
      "  7.13664293e-01 -1.84439480e-01  5.62474847e-01  1.10133603e-01\n",
      " -7.56292164e-01  3.58298570e-01  6.92528903e-01 -4.24314886e-01\n",
      " -3.94257843e-01 -5.29640168e-02  3.45504403e-01 -2.67459322e-02\n",
      "  1.46840379e-01  3.04584473e-01  7.72583485e-03 -2.27458328e-01\n",
      "  1.36594167e-02  4.11710352e-01 -1.30733132e-01 -7.62644708e-02\n",
      "  1.68319508e-01 -1.05861020e+00 -1.19143119e-03 -2.28546813e-01\n",
      " -3.72986674e-01  1.09299012e-01  1.79583535e-01  4.47252393e-03\n",
      " -1.40368849e-01  4.66066271e-01  1.26218572e-01  2.16003910e-01\n",
      "  4.24687833e-01  1.61736682e-01 -1.19382262e-01 -1.41520381e-01\n",
      " -4.25585151e-01 -6.44319057e-02 -2.05295861e-01 -5.00712335e-01\n",
      " -2.52815247e-01 -2.95724869e-01 -3.10073167e-01 -6.68842196e-01\n",
      " -7.24964082e-01 -1.16289549e-01 -2.24732250e-01 -1.61337748e-01\n",
      "  3.28135312e-01  1.00555770e-01  1.99593738e-01  3.78741384e-01\n",
      "  2.90558845e-01 -2.56396741e-01 -1.23025155e+00 -2.89010823e-01\n",
      " -3.57645601e-01  3.36359292e-01 -1.68753743e-01 -3.87225360e-01\n",
      " -8.26992989e-02  3.56380433e-01  1.20821521e-01 -6.11047328e-01\n",
      "  9.04102027e-02 -2.83634931e-01 -3.35993588e-01 -3.36830139e-01\n",
      " -3.57774715e-03  3.98344427e-01  5.83571829e-02 -1.70701265e-01\n",
      "  4.61612999e-01  4.59587276e-01 -5.69509745e-01  1.97617516e-01\n",
      " -2.95192987e-01 -2.16833353e-01  2.73930401e-01 -3.56242150e-01\n",
      " -1.89320430e-01  3.12833786e-01 -1.19180866e-01 -3.35007370e-01\n",
      "  3.01910907e-01 -7.57479370e-02  1.14850573e-01 -5.13700731e-02\n",
      " -2.35731930e-01  5.41041195e-01 -4.29317728e-02 -5.87085605e-01\n",
      "  4.31620300e-01 -3.74834359e-01 -6.01107441e-02  1.59965813e-01\n",
      "  2.65951931e-01 -7.89757445e-02  2.39072189e-01 -5.45774102e-01\n",
      " -2.37508580e-01 -3.44178468e-01  1.74120739e-02 -1.16569471e+00\n",
      " -1.40564710e-01  5.02886653e-01  2.61628151e-01 -7.26293504e-01\n",
      " -7.55395472e-01 -3.08262378e-01 -3.12900990e-02  6.19919837e-01\n",
      " -1.92375079e-01 -2.64311600e-02  2.88502336e-01 -2.65804883e-02\n",
      "  5.91538548e-02  6.30347431e-01 -3.40180814e-01 -9.41538066e-02\n",
      "  4.66440976e-01  7.40852281e-02  5.19875288e-02 -5.30970097e-02\n",
      "  6.02349520e-01  2.36399889e-01 -3.22351605e-01  1.42089427e-01\n",
      " -2.00897083e-01 -3.98206204e-01  6.21164024e-01 -1.55599847e-01\n",
      "  9.78913382e-02  7.09963799e-01  2.55349904e-01  1.95195097e-02\n",
      "  5.18825836e-03  6.70117199e-01  4.13327187e-01 -2.66455203e-01\n",
      "  2.37143606e-01 -5.33763468e-01  5.49671091e-02  4.41293061e-01\n",
      "  3.37091200e-02  4.73587126e-01 -7.37004578e-02 -3.07931714e-02\n",
      "  2.62678504e-01  2.69340366e-01 -7.14190722e-01  5.15878573e-02\n",
      " -2.72654802e-01  4.39622402e-01 -5.74226081e-01 -6.30378187e-01\n",
      " -5.67018986e-02  3.10666680e-01  2.11291060e-01  5.21970510e-01\n",
      "  6.09924734e-01 -4.63288426e-01  4.81123716e-01  3.00978631e-01\n",
      "  2.68652827e-01  6.56653941e-02  5.49600840e-01  5.25987446e-01\n",
      "  1.20807745e-01  2.18913034e-01  3.31000268e-01 -3.20321649e-01\n",
      " -2.38133147e-01  4.05892283e-02 -5.58041215e-01 -4.01499301e-01\n",
      "  8.26586336e-02  2.73882337e-02 -2.02608302e-01 -1.32254735e-01\n",
      " -2.15751737e-01  3.90428185e-01  4.76409942e-01  1.49899080e-01\n",
      " -1.70366362e-01  1.90112963e-01  2.30137348e-01 -3.37856114e-01\n",
      "  2.10619539e-01 -3.79617721e-01 -5.36418287e-03  3.35530192e-01\n",
      "  6.41129494e-01  4.31055337e-01  3.42286795e-01 -1.32179677e-01\n",
      " -1.85808048e-01  7.53844678e-01 -1.19067259e-01  6.70170069e-01]\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.encode('Se trata de una simple prueba del modelo generado')\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013d7e21",
   "metadata": {},
   "source": [
    "Now, we test our model, we encode a pair of sentences and check the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50bbd4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd45c956",
   "metadata": {},
   "source": [
    "## Upload the model to the Huggingface Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "648cbb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Login successful\n",
      "Your token has been saved to /home/ec2-user/.huggingface/token\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n",
      "\n",
      "git config --global credential.helper store\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99e38236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/huggingface_hub/utils/_deprecation.py:38: FutureWarning: Deprecated positional argument(s) used in 'create_repo': pass token='bertin-sts-cc-news-es' as keyword args. From version 0.12 passing these as positional arguments will result in an error,\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/huggingface_hub/hf_api.py:681: FutureWarning: `create_repo` now takes `token` as an optional positional argument. Be sure to adapt your code!\n",
      "  warnings.warn(\n",
      "Cloning https://huggingface.co/edumunozsala/bertin-sts-cc-news-es into local empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1664a185c0604cceabc7288cff67afc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 32.0k/476M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/edumunozsala/bertin-sts-cc-news-es\n",
      "   7c5066c..87bc588  main -> main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/edumunozsala/bertin-sts-cc-news-es/commit/87bc58875c522a7b370731c3e77efaa131d10cf5'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_to_hub(\n",
    "    \"bertin-sts-cc-news-es\", \n",
    "    #organization=\"embedding-data\",\n",
    "    train_datasets=[\"LeoCordoba/CC-NEWS-ES\"],\n",
    "    exist_ok=True, \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80ac95b",
   "metadata": {},
   "source": [
    "And that's all! Our Sentence Transformer model is now available in the Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4254db85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
